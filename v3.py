import cv2
import time
import numpy as np
import requests
import threading
import queue
import pytesseract
from ultralytics import YOLO
from rapidfuzz import fuzz, process
import RPi.GPIO as GPIO

# === 1. CONFIGURATION ===
IP_CAMERA_URL = "http://10.72.93.71:8080/shot.jpg"  # ‚ö†Ô∏è ‡πÉ‡∏ä‡πâ /shot.jpg ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∑‡πà‡∏ô
LED_PIN = 17

# Paths
TESSERACT_CMD = "/usr/bin/tesseract"
PLATE_MODEL_PATH = "/home/cn360/Desktop/LicensePlate-EdgeAI/LicensePlate.pt"
CODEPROV_MODEL_PATH = "/home/cn360/Desktop/LicensePlate-EdgeAI/CodeProv.pt"
PROVINCES_FILE = "/home/cn360/Desktop/LicensePlate-EdgeAI/thai_provinces.txt"
CAR_LIST_FILE = "/home/cn360/Desktop/LicensePlate-EdgeAI/Carlist.txt"
CONFIDENCE_THRESHOLD = 0.5
LANGUAGE = "tha"

# Global Variables ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πâ‡∏≤‡∏° Thread
latest_frame = None  # ‡πÄ‡∏Å‡πá‡∏ö‡∏†‡∏≤‡∏û‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
detection_result = None  # ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å AI (‡∏Å‡∏£‡∏≠‡∏ö, ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô)
frame_lock = threading.Lock()
running = True

# === 2. SETUP ===
GPIO.setmode(GPIO.BCM)
GPIO.setup(LED_PIN, GPIO.OUT)
GPIO.output(LED_PIN, False)
pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD

print("‚è≥ Loading AI Models (Background)...")
# ‡πÇ‡∏´‡∏•‡∏î Model ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ‡πÄ‡∏•‡∏¢
plate_model = YOLO(PLATE_MODEL_PATH)
codeprov_model = YOLO(CODEPROV_MODEL_PATH)

# Load Lists
try:
    with open(PROVINCES_FILE, encoding="utf-8") as f:
        thai_provinces = [line.strip() for line in f.readlines()]
    with open(CAR_LIST_FILE, encoding="utf-8") as f:
        car_list = [line.strip() for line in f.readlines()]
except Exception:
    thai_provinces, car_list = [], []
print("‚úÖ Ready!")

# === 3. AI WORKER THREAD ===
def ai_worker():
    global latest_frame, detection_result, running
    
    print("ü§ñ AI Brain Started...")
    while running:
        img_to_process = None
        
        # 1. ‡πÅ‡∏≠‡∏ö‡πÑ‡∏õ‡∏à‡∏¥‡πä‡∏Å‡∏†‡∏≤‡∏û‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏°‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        with frame_lock:
            if latest_frame is not None:
                img_to_process = latest_frame.copy()
        
        if img_to_process is None:
            time.sleep(0.1)
            continue

        # 2. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• (‡∏Å‡∏¥‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ 0.X ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏´‡∏•‡∏±‡∏Å)
        # --- (Logic ‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì) ---
        # ‡∏´‡∏≤‡∏õ‡πâ‡∏≤‡∏¢
        results = plate_model(img_to_process, conf=CONFIDENCE_THRESHOLD, verbose=False)[0]
        found_plate = False
        
        for box in results.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
            
            # ‡∏ï‡∏±‡∏î‡∏†‡∏≤‡∏û‡∏õ‡πâ‡∏≤‡∏¢
            h, w = img_to_process.shape[:2]
            crop = img_to_process[max(0, y1):min(h, y2), max(0, x1):min(w, x2)]
            
            # ‡πÅ‡∏¢‡∏Å‡πÄ‡∏•‡∏Ç/‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
            res_ocr = codeprov_model(crop, conf=CONFIDENCE_THRESHOLD, verbose=False)[0]
            code_part, prov_part = None, None
            
            for b in res_ocr.boxes:
                cx1, cy1, cx2, cy2 = map(int, b.xyxy[0].tolist())
                cid = int(b.cls[0])
                p_img = crop[max(0, cy1):min(crop.shape[0], cy2), max(0, cx1):min(crop.shape[1], cx2)]
                if cid == 0: code_part = p_img
                elif cid == 1: prov_part = p_img
            
            # OCR
            full_text = ""
            if code_part is not None:
                gray = cv2.cvtColor(code_part, cv2.COLOR_BGR2GRAY)
                full_text += pytesseract.image_to_string(gray, lang=LANGUAGE, config='--psm 7').strip()
            
            if prov_part is not None:
                gray = cv2.cvtColor(prov_part, cv2.COLOR_BGR2GRAY)
                txt = pytesseract.image_to_string(gray, lang=LANGUAGE, config='--psm 7').strip()
                match = process.extractOne(txt, thai_provinces, scorer=fuzz.ratio)
                if match and match[1] >= 30: full_text += " " + match[0]
            
            clean_text = full_text.replace(" ", "")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå
            is_authorized = False
            for c in car_list:
                if clean_text in c or c in clean_text:
                    is_authorized = True
                    break

            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏´‡∏•‡∏±‡∏Å
            detection_result = {
                "box": (x1, y1, x2, y2),
                "text": full_text,
                "auth": is_authorized
            }
            
            # ‡∏ñ‡πâ‡∏≤‡∏ú‡πà‡∏≤‡∏ô ‡πÉ‡∏´‡πâ‡∏™‡∏±‡πà‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏õ‡∏£‡∏∞‡∏ï‡∏π (‡πÅ‡∏¢‡∏Å Thread ‡∏≠‡∏µ‡∏Å‡∏ó‡∏µ‡∏Å‡∏±‡∏ô‡πÄ‡∏´‡∏ô‡∏µ‡∏¢‡∏ß)
            if is_authorized:
                threading.Thread(target=open_gate_action, daemon=True).start()
            elif clean_text:
                threading.Thread(target=blink_action, daemon=True).start()
                
            found_plate = True
            break # ‡πÄ‡∏à‡∏≠‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏¢‡∏∏‡∏î‡∏´‡∏≤
            
        if not found_plate:
            detection_result = None # ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡πá‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏¥‡πâ‡∏á

        # ‡∏û‡∏±‡∏Å‡∏ô‡∏¥‡∏î‡∏ô‡∏∂‡∏á ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ CPU ‡∏£‡πâ‡∏≠‡∏ô‡∏à‡∏±‡∏î (‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ)
        time.sleep(0.01) 

# === 4. HARDWARE ACTIONS ===
def open_gate_action():
    print("üü¢ GATE OPEN")
    GPIO.output(LED_PIN, True)
    time.sleep(3)
    GPIO.output(LED_PIN, False)

def blink_action():
    for _ in range(3):
        GPIO.output(LED_PIN, True); time.sleep(0.1)
        GPIO.output(LED_PIN, False); time.sleep(0.1)

# === 5. MAIN LOOP (DISPLAY) ===
# ‡πÄ‡∏£‡∏¥‡πà‡∏° AI Thread
ai_thread = threading.Thread(target=ai_worker, daemon=True)
ai_thread.start()

print("üöÄ Starting Display...")
cap_url = IP_CAMERA_URL

try:
    while True:
        # 1. ‡∏î‡∏∂‡∏á‡∏†‡∏≤‡∏û (Snapshot)
        try:
            resp = requests.get(cap_url, timeout=2)
            arr = np.asarray(bytearray(resp.content), dtype=np.uint8)
            frame = cv2.imdecode(arr, -1)
            
            if frame is not None:
                # ‡∏¢‡πà‡∏≠‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏∑‡πà‡∏ô
                frame = cv2.resize(frame, (640, 480))
                
                # ‡∏™‡πà‡∏á‡∏†‡∏≤‡∏û‡πÑ‡∏õ‡πÉ‡∏´‡πâ AI (Update Global Variable)
                with frame_lock:
                    latest_frame = frame.copy()
                
                # 2. ‡∏ß‡∏≤‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å AI (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
                # ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡∏ß‡∏≤‡∏î‡∏ã‡πâ‡∏≥‡πÑ‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ ‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤ AI ‡∏à‡∏∞‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏°‡∏≤ (‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡∏≤‡∏Å‡∏£‡∏∞‡∏û‡∏£‡∏¥‡∏ö‡∏ô‡πâ‡∏≠‡∏¢‡∏•‡∏á)
                if detection_result:
                    x1, y1, x2, y2 = detection_result["box"]
                    text = detection_result["text"]
                    color = (0, 255, 0) if detection_result["auth"] else (0, 0, 255)
                    
                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                    cv2.putText(frame, text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

                cv2.imshow("Smart Gate (Async)", frame)
            
        except Exception as e:
            print(f"Cam Error: {e}")
            time.sleep(1)

        if cv2.waitKey(1) == ord('q'):
            running = False
            break

except KeyboardInterrupt:
    pass
finally:
    running = False
    cv2.destroyAllWindows()
    GPIO.cleanup()

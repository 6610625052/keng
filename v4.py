import cv2
import pytesseract
import time
from ultralytics import YOLO
import numpy as np
from rapidfuzz import fuzz, process

# === CONFIG ===
TESSERACT_CMD = "/usr/bin/tesseract"
LANGUAGE = "tha+eng"
PLATE_MODEL_PATH = "/home/cn360/Desktop/LicensePlate-EdgeAI/LicensePlate.pt"
CODEPROV_MODEL_PATH = "/home/cn360/Desktop/LicensePlate-EdgeAI/CodeProv.pt"
CONFIDENCE_THRESHOLD = 0.5
IP_CAM_URL = "http://10.72.93.71:8080/video" # <--- à¹ƒà¸ªà¹ˆ URL à¸‚à¸­à¸‡à¸„à¸¸à¸“à¸—à¸µà¹ˆà¸™à¸µà¹ˆ

# === INIT ===
pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD
print("Loading Models...")
plate_model = YOLO(PLATE_MODEL_PATH)
codeprov_model = YOLO(CODEPROV_MODEL_PATH)
print("Models Loaded.")

with open("/home/cn360/Desktop/LicensePlate-EdgeAI/thai_provinces.txt", encoding="utf-8") as f:
    thai_provinces = [line.strip() for line in f.readlines()]

# === UTILS (à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡) ===
def safe_crop(img, x1, y1, x2, y2):
    h, w = img.shape[:2]
    return img[max(0, y1):min(h, y2), max(0, x1):min(w, x2)]

def preprocess_for_ocr(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    contrast = clahe.apply(gray)
    _, thresh = cv2.threshold(contrast, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    return thresh

def match_province(input_text, threshold=75):
    best_match = process.extractOne(input_text, thai_provinces, scorer=fuzz.ratio)
    if best_match and best_match[1] >= threshold:
        return best_match[0]
    return None

# === CORE FUNCTIONS ===
def process_frame(img):
    # 1. Detect Plate
    plate_results = plate_model(img, conf=CONFIDENCE_THRESHOLD, verbose=False)[0]
    
    for box in plate_results.boxes:
        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
        cropped_plate = safe_crop(img, x1, y1, x2, y2)
        
        # à¸§à¸²à¸”à¸à¸£à¸­à¸šà¸ªà¸µà¹ˆà¹€à¸«à¸¥à¸µà¹ˆà¸¢à¸¡à¸ªà¸µà¹€à¸‚à¸µà¸¢à¸§à¸šà¸™à¸ à¸²à¸žà¸ˆà¸£à¸´à¸‡à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸£à¸¹à¹‰à¸§à¹ˆà¸²à¸ˆà¸±à¸šà¹€à¸ˆà¸­
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)

        # 2. Detect Text inside Plate
        ocr_results = codeprov_model(cropped_plate, conf=CONFIDENCE_THRESHOLD, verbose=False)[0]
        code_part, province_part = None, None

        for ocr_box in ocr_results.boxes:
            px1, py1, px2, py2 = map(int, ocr_box.xyxy[0].tolist())
            cls_id = int(ocr_box.cls[0])
            part_img = safe_crop(cropped_plate, px1, py1, px2, py2)
            
            if cls_id == 0: # Code
                code_part = preprocess_for_ocr(part_img)
            elif cls_id == 1: # Province
                province_part = preprocess_for_ocr(part_img)

        # 3. OCR
        code_text = pytesseract.image_to_string(code_part, lang=LANGUAGE, config='--psm 7').strip() if code_part is not None else ''
        province_raw = pytesseract.image_to_string(province_part, lang=LANGUAGE, config='--psm 7').strip() if province_part is not None else ''
        
        province_clean = match_province(province_raw)
        final_province = province_clean if province_clean else province_raw

        return f"{code_text} {final_province}", img
    
    return None, img

# === MAIN LOOP ===
def main():
    print(f"Connecting to Camera: {IP_CAM_URL}")
    cap = cv2.VideoCapture(IP_CAM_URL)

    # à¸•à¸±à¹‰à¸‡à¸„à¹ˆà¸²à¸‚à¸™à¸²à¸”à¸ à¸²à¸žà¹€à¸žà¸·à¹ˆà¸­à¸¥à¸”à¸ à¸²à¸£à¸°à¹€à¸„à¸£à¸·à¹ˆà¸­à¸‡ (Optional)
    # cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    # cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

    if not cap.isOpened():
        print("Error: Cannot open camera.")
        return

    last_detected_text = ""
    last_detected_time = 0
    COOLDOWN_SECONDS = 5.0  # à¹€à¸§à¸¥à¸²à¸«à¸™à¹ˆà¸§à¸‡ à¸–à¹‰à¸²à¹€à¸ˆà¸­à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¹€à¸”à¸´à¸¡à¸ˆà¸°à¹„à¸¡à¹ˆ Print à¸‹à¹‰à¸³à¸ à¸²à¸¢à¹ƒà¸™ 5 à¸§à¸´à¸™à¸²à¸—à¸µ

    print("Starting Loop. Press 'q' to exit.")

    while True:
        ret, frame = cap.read()
        if not ret:
            print("Error: Failed to read frame.")
            # à¸–à¹‰à¸²à¸à¸¥à¹‰à¸­à¸‡à¸«à¸¥à¸¸à¸” à¹ƒà¸«à¹‰à¸¥à¸­à¸‡à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¹ƒà¸«à¸¡à¹ˆ à¸«à¸£à¸·à¸­ break
            time.sleep(1) 
            continue

        # à¸ªà¹ˆà¸‡à¸ à¸²à¸žà¹„à¸›à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥
        result_text, display_frame = process_frame(frame)

        if result_text:
            current_time = time.time()
            # à¹€à¸Šà¹‡à¸„à¸§à¹ˆà¸²à¸—à¸°à¹€à¸šà¸µà¸¢à¸™à¸‹à¹‰à¸³à¸à¸±à¸šà¹€à¸¡à¸·à¹ˆà¸­à¸à¸µà¹‰à¹„à¸«à¸¡ à¹à¸¥à¸°à¹€à¸§à¸¥à¸²à¸œà¹ˆà¸²à¸™à¹„à¸›à¸™à¸²à¸™à¸žà¸­à¸«à¸£à¸·à¸­à¸¢à¸±à¸‡
            if result_text != last_detected_text or (current_time - last_detected_time > COOLDOWN_SECONDS):
                
                print(f"ðŸ“Œ DETECTED: {result_text}") # <--- Output à¸•à¸£à¸‡à¸™à¸µà¹‰
                
                last_detected_text = result_text
                last_detected_time = current_time
                
                # à¸šà¸±à¸™à¸—à¸¶à¸à¸ à¸²à¸žà¹€à¸¡à¸·à¹ˆà¸­à¹€à¸ˆà¸­
                cv2.imwrite("last_detected.jpg", display_frame)

        # à¹à¸ªà¸”à¸‡à¸ à¸²à¸žà¸ªà¸” (Live View)
        cv2.imshow("LPR System (Press 'q' to exit)", display_frame)

        # à¸à¸” 'q' à¹€à¸žà¸·à¹ˆà¸­à¸­à¸­à¸
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
